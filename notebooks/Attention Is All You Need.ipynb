{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4e8c56-e54c-49bd-8f51-24365eedf244",
   "metadata": {},
   "source": [
    "## Attention Is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa25624-e9fa-401c-a0f7-5f4a6831410f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623535c-5328-4138-9952-d99c269e7950",
   "metadata": {},
   "source": [
    "In 2017, researchers from Google published a paper titled [**Attention Is All You Need**](https://arxiv.org/pdf/1706.03762), introducing a novel architecture called the **Transformer** in the context of machine translation tasks. This architecture has significantly influenced AI research and inspired many other applications.\n",
    "\n",
    "The **Transformer** is at the heart of modern **Large Language Models** (LLMs), the most famous of which is [**ChatGPT**](https://chat.openai.com/) from [**OpenAI**](https://openai.com/). **ChatGPT** is based on the **GPT** architecture, which stands for **Generative Pre-trained Transformer** and serves as an assistant chatbot. Another notable application of the **Transformer** architecture is **BERT**, described in the [**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**](https://arxiv.org/pdf/1810.04805) paper. The **BERT** model is used in many tasks like sentiment analysis, question answering (Q&A), and more.\n",
    "\n",
    "In this tutorial, we will delve deep into the [**Attention Is All You Need**](https://arxiv.org/pdf/1706.03762) paper, exploring the **Transformer** architecture in depth, from theory to code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581538a8-c785-4409-8c4f-71fa16bef40d",
   "metadata": {},
   "source": [
    "<center> <img src=\"https://www.researchgate.net/publication/323904682/figure/fig1/AS:606458626465792@1521602412057/The-Transformer-model-architecture.png\" width=\"300px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b32bd-bebc-4125-886c-d4ad4e4afebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
